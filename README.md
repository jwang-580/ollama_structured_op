# LLM Extraction of Clinical Notes

This project implements automated information extraction from clinical notes using local Large Language Models (LLMs). The ground truth is generated by gpt-4o. The local LLMs are implemented using Ollama, with llama3.3-70.6B-Q4-quantized model as the default model. The sample notes are five notes in the field of bone marrow transplantation obtained from MIMIC-IV. 

## Setup

1. Clone the repository
2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Create a `.env` file in the root directory and add your OpenAI API key:

```
OAI_API_KEY=your_api_key_here
```

4. Install Ollama:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

5. Download the llama3.3 70b Q4-quantized model:

```bash
ollama pull llama3.3
```

## Project Structure

- `ollama_structured_op.py`: Implementation using Ollama models
- `openai_structured_op.py`: Implementation using OpenAI's GPT-4o
- `config.py`: Configuration and environment variable management
- `data_fields.py`: Pydantic models to define data fields to be extracted
- `utils.py`: Utility functions for note parsing
- `eval.py`: Evaluation metrics
- `figure.ipynb`: Jupyter notebook to generate results figures

## Usage

### Data Extraction Fields

The system extracts the following information from clinical notes:

1. Primary Diagnosis
   - Primary disease
   - Conditioning regimen type
   - Conditioning regimen
   - Donor type
   - Transplant complications

2. Hospital Course
   - Reason for admission
   - Problem list

3. Lab Results
   - WBC (admission/discharge)
   - Neutrophils (admission/discharge)
   - Hemoglobin (admission/discharge)
   - Platelets (admission/discharge)
   - Total Bilirubin (admission/discharge)
   - Calcium (admission/discharge)

4. Medications
   - Admission medications
   - Discharge medications


### Ollama Implementation

The Ollama implementation supports two methods of extraction:

1. Whole Note Method (--method 1)
2. Section-by-Section Method (--method 2)

```bash
python ollama_structured_op.py --method [1|2] --model [model_name]
```
Example:

```bash
python ollama_structured_op.py --method 2 --model llama3.3
```
If to test additional ollama models, please refer to https://ollama.com/search to download additional models, and update the `AVAILABLE_MODELS` dictionary in `ollama_structured_op.py`. 

### OpenAI Implementation

The OpenAI implementation is straightforward, using the `gpt-4o` model. 

```bash
python openai_structured_op.py 
```

### Output

Results are saved in the `results` directory as CSV files with the following naming convention:
- Ollama: `notes_extracts_{model}_method{method}_{timestamp}.csv`
- OpenAI: `notes_extracts_gpt4o_{timestamp}.csv`


## Evaluation

### Metrics

The evaluation system calculates four key metrics for each field:
- Accuracy
- Precision
- Recall
- F1 Score

### Running Evaluation

To evaluate extraction results against ground truth:

```bash
python eval.py --ground-truth path/to/ground_truth.csv --test path/to/test_results.csv
```

### Output

The evaluation results are saved in two formats:

1. Console output showing:
   - Detailed metrics for each field
   - Overall metrics across all fields

2. CSV file in the `results` directory:
   - Filename: `evaluation_results_{timestamp}.csv`
   - Contains accuracy, precision, recall, and F1 scores for each field



## License

PASS